import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import cv2

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import torchvision.datasets as datasets


def get_data(slice=5):
    data_root = 'Dataset/'

    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
    ])

    # Collect datasets from each category folder
    all_data = []
    categories = ['decks', 'pavements', 'walls']

    for category in categories:
        path = os.path.join(data_root, category)
        dataset = datasets.ImageFolder(root=path, transform=transform)
        all_data.append(dataset)

    # Combine all datasets
    combined_data = torch.utils.data.ConcatDataset(all_data)

    # Create a subset using slicing
    sub_dataset = torch.utils.data.Subset(combined_data, indices=range(0, len(combined_data), slice))

    # All ImageFolder datasets share the same classes, so we can get them from one
    class_names = all_data[0].classes

    return sub_dataset, class_names

# Load dataset
image_dataset, class_names = get_data(slice=1)

# Print total number of images
print("Number of images:", len(image_dataset))
print("Class names:", class_names)

import os
import torch
import pickle
from torchvision import datasets, transforms
from torch.utils.data import random_split, ConcatDataset
import torchvision.transforms.functional as TF
from typing import Tuple
from torchvision.utils import save_image
from tqdm import tqdm

### Preprocessing ###
# Denoising transform
class Denoise:
    def __call__(self, img):
        return TF.gaussian_blur(img, kernel_size=3)     # Apply Gaussian blur for denoising

# Transformations
train_transform = transforms.Compose([
    transforms.Resize((256, 256)),          # Resize to 256x256
    transforms.RandomHorizontalFlip(),      # Randomly flip the image horizontally
    transforms.RandomRotation(15),          # Randomly rotate the image by 15 degrees
    transforms.ColorJitter(brightness=0.2, 
                           contrast=0.2),   # Randomly change brightness and contrast
    Denoise(),
    transforms.ToTensor(),                  # Convert image to tensor (scales to [0, 1])
])

val_test_transform = transforms.Compose([
    transforms.Resize((256, 256)),          # Resize to 256x256
    Denoise(),
    transforms.ToTensor(),
])


# Load combined dataset
def load_combined_dataset(transform) -> Tuple[ConcatDataset, list]:
    root = 'Dataset'
    categories = ['decks', 'pavements', 'walls']
    datasets_list = []

    for category in categories:
        path = os.path.join(root, category)
        dataset = datasets.ImageFolder(path, transform=transform)
        datasets_list.append(dataset)

    return ConcatDataset(datasets_list), datasets_list[0].classes

# Load dataset with test transform (neutral)
full_dataset, class_names = load_combined_dataset(val_test_transform)

# Split 70% train, 15% val, 15% test
train_size = int(0.7 * len(full_dataset))
val_size = int(0.15 * len(full_dataset))
test_size = len(full_dataset) - train_size - val_size

train_set, val_set, test_set = random_split(full_dataset, [train_size, val_size, test_size])

def save_dataset_as_folder(dataset, save_path, split_name, class_names):
    image_folder = os.path.join(save_path, split_name, "images")
    label_csv = os.path.join(save_path, split_name, "labels.csv")
    os.makedirs(image_folder, exist_ok=True)

    data = []

    for idx, (image, label) in tqdm(enumerate(dataset), total=len(dataset), desc=f"Saving {split_name}"):
        filename = f"{split_name}_{idx:05d}.png"
        filepath = os.path.join(image_folder, filename)
        save_image(image, filepath)  # Save image
        data.append({"filename": filename, "label": class_names[label]})

    df = pd.DataFrame(data)
    df.to_csv(label_csv, index=False)
    print(f"âœ… {split_name} saved to {image_folder} with labels in {label_csv}")

train_set,class_names = load_combined_dataset(train_transform)


### Balance the train dataset ###
from torch.utils.data import Subset
import numpy as np
from collections import Counter

# Get indices of each class
class_0_indices = [i for i, (_, label) in enumerate(train_set) if label == 0]
class_1_indices = [i for i, (_, label) in enumerate(train_set) if label == 1]

# Determine the minimum class size
min_class_size = min(len(class_0_indices), len(class_1_indices))

# Randomly sample indices to balance the classes
balanced_class_0_indices = np.random.choice(class_0_indices, min_class_size, replace=False)
balanced_class_1_indices = np.random.choice(class_1_indices, min_class_size, replace=False)

# Combine and shuffle the indices
balanced_indices = np.concatenate([balanced_class_0_indices, balanced_class_1_indices])
np.random.shuffle(balanced_indices)

# Create a balanced dataset
balanced_train_set = Subset(train_set, balanced_indices)

# Verify the new class distribution
balanced_label_counts = Counter([label for _, label in balanced_train_set])
print("Balanced class distribution:", balanced_label_counts)

save_dataset_as_folder(balanced_train_set, "artifact_folder", "train", class_names)
save_dataset_as_folder(val_set, "artifact_folder", "val", class_names)
save_dataset_as_folder(test_set, "artifact_folder", "test", class_names)