{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b77511e",
   "metadata": {},
   "source": [
    "Reduce overfiting of MobileNetV3_concrete_crack_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e40fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
    "import torchvision.models as models\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_start_method('spawn', force=True)\n",
    "\n",
    "from torchvision import  models,transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights, mobilenet_v3_small, mobilenet_v3_large, MobileNet_V3_Small_Weights, MobileNet_V3_Large_Weights\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1063d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "087d70c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcreteCrackDataset(Dataset):\n",
    "  \n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.label_map = {\"Non-cracked\": 0, \"Cracked\": 1}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.annotations.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        label_str = self.annotations.iloc[idx, 1]\n",
    "        \n",
    "        # Handle case sensitivity and strip any whitespace\n",
    "        label_str = label_str.strip()\n",
    "        if label_str.lower() == \"non-cracked\" or label_str.lower() == \"non-crack\" or label_str.lower() == \"non-cracked\":\n",
    "            label = 0\n",
    "        elif label_str.lower() == \"cracked\" or label_str.lower() == \"crack\":\n",
    "            label = 1\n",
    "        else:\n",
    "            print(f\"Unknown label: {label_str}, defaulting to Non-cracked (0)\")\n",
    "            label = 0\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c61237cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained MobileNetV3 model\n",
    "def get_MobileNetV3_model(num_classes=2):\n",
    "\n",
    "    weights = MobileNet_V3_Large_Weights.DEFAULT\n",
    "    model = mobilenet_v3_large(weights=weights)\n",
    "    model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77063920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Get predictions\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Update statistics\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "            # Store predictions and targets for additional metrics\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_preds, average='binary')\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": torch.tensor(accuracy),\n",
    "        \"precision\": torch.tensor(precision),\n",
    "        \"recall\": torch.tensor(recall),\n",
    "        \"f1\": torch.tensor(f1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3210508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, data_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, targets in tqdm(data_loader, desc=\"Training\"):\n",
    "        try:\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Clip gradients to prevent explosion\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update statistics\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "            # Print loss occasionally\n",
    "            if num_batches % 50 == 0:\n",
    "                accuracy = 100 * correct / total\n",
    "                print(f\"Batch {num_batches}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Calculate average loss and accuracy\n",
    "    if num_batches == 0:\n",
    "        print(\"WARNING: No valid batches in this epoch!\")\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f\"Processed {num_batches} batches\")\n",
    "    print(f\"Training Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a1ba79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs):\n",
    "    best_accuracy = 0.0\n",
    "    best_model_wts = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "        \n",
    "        # Train for one epoch\n",
    "        epoch_loss, train_accuracy = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        print(f\"Training Loss: {epoch_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%\")\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_metrics = evaluate(model, val_loader, device)\n",
    "        val_accuracy = val_metrics['accuracy'].item()\n",
    "        val_f1 = val_metrics['f1'].item()\n",
    "        \n",
    "        print(f\"Validation Accuracy: {val_accuracy:.2f}%, F1-Score: {val_f1:.4f}\")\n",
    "        \n",
    "        # Save best model based on accuracy\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            best_model_wts = model.state_dict().copy()\n",
    "            torch.save(best_model_wts, f'best_model_epoch_{epoch+1}.pth')\n",
    "            print(f\"Saved best model with Accuracy: {best_accuracy:.2f}%\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "294530c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Set random seeds for reproducibility\n",
    "    set_seed(42)\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # MobileNetV3 typically uses 224x224\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    train_dataset = ConcreteCrackDataset('../artifact_folder/train/labels.csv', '../artifact_folder/train/images', transform)\n",
    "    val_dataset = ConcreteCrackDataset('../artifact_folder/val/labels.csv', '../artifact_folder/val/images', transform)\n",
    "    test_dataset = ConcreteCrackDataset('../artifact_folder/test/labels.csv', '../artifact_folder/test/images', transform)\n",
    "    \n",
    "    # Check if datasets are loaded correctly\n",
    "    print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "    print(f\"Val dataset size: {len(val_dataset)}\")\n",
    "    print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "    print(f\"----------------------------------------------------------------------------\")\n",
    "    \n",
    "    # Verify a few samples to ensure labels are valid\n",
    "    print(\"Checking a few samples from training set:\")\n",
    "    for i in range(min(3, len(train_dataset))):\n",
    "        img, label = train_dataset[i]\n",
    "        print(f\"Sample {i} - Image shape: {img.shape}, Label: {label}\")\n",
    "\n",
    "    # Use a batch size suitable for MobileNetV3\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    # Get MobileNetV3 model\n",
    "    model = get_MobileNetV3_model(num_classes=2)  # 2 classes: Non-cracked (0) / Cracked (1)\n",
    "    model.to(device)\n",
    "    # Define loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Define optimizer and learning rate scheduler\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    # Use learning rate scheduler to reduce lr by 0.1 every 3 epochs\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "    print(f\"----------------------------------------------------------------------------\")\n",
    "    # Train model\n",
    "    print(\"Starting training...\")\n",
    "    start_time = time.time()\n",
    "    model, best_accuracy = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        device,\n",
    "        num_epochs=10)\n",
    "    end_time = time.time()\n",
    "    print(f\"Training completed in {(end_time - start_time) / 60:.2f} minutes\")\n",
    "    print(f\"Best validation accuracy: {best_accuracy:.2f}%\")\n",
    "    torch.save(model.state_dict(), 'Optimize_MobileNetV3_concrete_crack_detector.pth')\n",
    "    print(f\"----------------------------------------------------------------------------\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9088e516",
   "metadata": {},
   "source": [
    "Run Entire Processes to get MobileNetV3_concrete_crack_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832a5f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Train dataset size: 16968\n",
      "Val dataset size: 8413\n",
      "Test dataset size: 8415\n",
      "----------------------------------------------------------------------------\n",
      "Checking a few samples from training set:\n",
      "Sample 0 - Image shape: torch.Size([3, 224, 224]), Label: 0\n",
      "Sample 1 - Image shape: torch.Size([3, 224, 224]), Label: 0\n",
      "Sample 2 - Image shape: torch.Size([3, 224, 224]), Label: 0\n",
      "----------------------------------------------------------------------------\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 50/531 [02:45<25:46,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50, Loss: 0.8710, Accuracy: 72.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 100/531 [05:39<23:40,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100, Loss: 0.3337, Accuracy: 76.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 150/531 [08:24<20:24,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 150, Loss: 0.2964, Accuracy: 76.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 200/531 [11:08<17:46,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200, Loss: 0.5450, Accuracy: 77.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|████▋     | 250/531 [13:51<14:57,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250, Loss: 0.3985, Accuracy: 78.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▋    | 300/531 [16:32<12:27,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300, Loss: 0.5417, Accuracy: 78.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|██████▌   | 350/531 [19:13<09:40,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 350, Loss: 0.6813, Accuracy: 78.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 400/531 [21:59<07:00,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400, Loss: 0.2417, Accuracy: 79.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▍ | 450/531 [24:41<04:20,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 450, Loss: 0.2500, Accuracy: 79.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 500/531 [27:23<01:39,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500, Loss: 0.2950, Accuracy: 79.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 531/531 [29:01<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 531 batches\n",
      "Training Loss: 0.4372, Accuracy: 80.13%\n",
      "Training Loss: 0.4372, Training Accuracy: 80.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 263/263 [05:19<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.21%\n",
      "Precision: 0.5444\n",
      "Recall: 0.7937\n",
      "F1-Score: 0.6458\n",
      "Confusion Matrix:\n",
      "[[6356  821]\n",
      " [ 255  981]]\n",
      "Validation Accuracy: 87.21%, F1-Score: 0.6458\n",
      "Saved best model with Accuracy: 87.21%\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 50/531 [02:41<26:13,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50, Loss: 0.3623, Accuracy: 80.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 100/531 [05:22<22:57,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100, Loss: 0.2573, Accuracy: 82.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 150/531 [08:02<20:18,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 150, Loss: 0.2455, Accuracy: 82.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 200/531 [10:42<17:31,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200, Loss: 0.3636, Accuracy: 83.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|████▋     | 250/531 [13:21<14:54,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250, Loss: 0.3353, Accuracy: 83.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▋    | 300/531 [16:00<12:17,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300, Loss: 0.2611, Accuracy: 83.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|██████▌   | 350/531 [18:40<09:35,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 350, Loss: 0.2625, Accuracy: 83.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 400/531 [21:21<06:59,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400, Loss: 0.4222, Accuracy: 83.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▍ | 450/531 [24:03<04:23,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 450, Loss: 0.3560, Accuracy: 83.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 500/531 [26:46<01:42,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500, Loss: 0.1979, Accuracy: 83.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 531/531 [28:25<00:00,  3.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 531 batches\n",
      "Training Loss: 0.3729, Accuracy: 83.82%\n",
      "Training Loss: 0.3729, Training Accuracy: 83.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 263/263 [05:25<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.61%\n",
      "Precision: 0.4353\n",
      "Recall: 0.8471\n",
      "F1-Score: 0.5751\n",
      "Confusion Matrix:\n",
      "[[5819 1358]\n",
      " [ 189 1047]]\n",
      "Validation Accuracy: 81.61%, F1-Score: 0.5751\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 50/531 [02:42<25:48,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50, Loss: 0.2335, Accuracy: 88.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 100/531 [05:23<22:59,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100, Loss: 0.2656, Accuracy: 86.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 150/531 [08:04<20:56,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 150, Loss: 0.3001, Accuracy: 86.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 200/531 [10:47<17:44,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200, Loss: 0.3238, Accuracy: 86.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|████▋     | 250/531 [13:28<15:01,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250, Loss: 0.4535, Accuracy: 86.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▋    | 300/531 [16:10<12:20,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300, Loss: 0.3007, Accuracy: 86.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|██████▌   | 350/531 [18:53<09:45,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 350, Loss: 0.4110, Accuracy: 86.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 400/531 [21:40<07:30,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400, Loss: 0.3731, Accuracy: 86.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▍ | 450/531 [25:15<06:05,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 450, Loss: 0.2284, Accuracy: 86.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 500/531 [28:58<02:16,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500, Loss: 0.1199, Accuracy: 86.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 531/531 [31:12<00:00,  3.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 531 batches\n",
      "Training Loss: 0.3321, Accuracy: 86.01%\n",
      "Training Loss: 0.3321, Training Accuracy: 86.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 263/263 [06:08<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.91%\n",
      "Precision: 0.8851\n",
      "Recall: 0.6731\n",
      "F1-Score: 0.7647\n",
      "Confusion Matrix:\n",
      "[[7069  108]\n",
      " [ 404  832]]\n",
      "Validation Accuracy: 93.91%, F1-Score: 0.7647\n",
      "Saved best model with Accuracy: 93.91%\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 50/531 [03:41<35:23,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50, Loss: 0.3980, Accuracy: 88.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 100/531 [07:23<31:49,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100, Loss: 0.1772, Accuracy: 89.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 150/531 [11:08<34:49,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 150, Loss: 0.2088, Accuracy: 90.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 200/531 [15:01<26:33,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200, Loss: 0.2649, Accuracy: 90.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|████▋     | 250/531 [17:46<15:05,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250, Loss: 0.2553, Accuracy: 90.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▋    | 300/531 [20:27<12:16,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300, Loss: 0.1339, Accuracy: 90.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|██████▌   | 350/531 [23:07<09:40,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 350, Loss: 0.3871, Accuracy: 90.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 400/531 [25:48<07:04,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400, Loss: 0.2033, Accuracy: 90.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▍ | 450/531 [28:28<04:24,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 450, Loss: 0.2303, Accuracy: 91.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 500/531 [31:22<01:49,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500, Loss: 0.3152, Accuracy: 90.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 531/531 [33:08<00:00,  3.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 531 batches\n",
      "Training Loss: 0.2267, Accuracy: 91.04%\n",
      "Training Loss: 0.2267, Training Accuracy: 91.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 263/263 [05:45<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.86%\n",
      "Precision: 0.6102\n",
      "Recall: 0.8576\n",
      "F1-Score: 0.7131\n",
      "Confusion Matrix:\n",
      "[[6500  677]\n",
      " [ 176 1060]]\n",
      "Validation Accuracy: 89.86%, F1-Score: 0.7131\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 50/531 [02:55<28:09,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50, Loss: 0.2527, Accuracy: 93.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 100/531 [05:48<24:37,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100, Loss: 0.3280, Accuracy: 92.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 150/531 [08:40<21:47,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 150, Loss: 0.2085, Accuracy: 92.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 200/531 [11:32<18:58,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200, Loss: 0.0706, Accuracy: 92.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|████▋     | 250/531 [14:24<16:18,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250, Loss: 0.1007, Accuracy: 92.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▋    | 300/531 [17:18<13:24,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300, Loss: 0.0867, Accuracy: 92.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|██████▌   | 350/531 [20:05<09:41,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 350, Loss: 0.1525, Accuracy: 92.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 400/531 [22:50<07:00,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400, Loss: 0.1476, Accuracy: 92.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▍ | 450/531 [25:34<04:49,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 450, Loss: 0.2859, Accuracy: 92.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 500/531 [28:18<01:40,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500, Loss: 0.1220, Accuracy: 92.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 531/531 [29:55<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 531 batches\n",
      "Training Loss: 0.1845, Accuracy: 93.02%\n",
      "Training Loss: 0.1845, Training Accuracy: 93.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 263/263 [05:18<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.32%\n",
      "Precision: 0.7046\n",
      "Recall: 0.8220\n",
      "F1-Score: 0.7588\n",
      "Confusion Matrix:\n",
      "[[6751  426]\n",
      " [ 220 1016]]\n",
      "Validation Accuracy: 92.32%, F1-Score: 0.7588\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 50/531 [02:45<25:45,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50, Loss: 0.0632, Accuracy: 93.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 100/531 [05:30<23:21,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100, Loss: 0.1528, Accuracy: 94.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 150/531 [08:11<20:24,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 150, Loss: 0.2871, Accuracy: 94.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 200/531 [10:53<17:48,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200, Loss: 0.0420, Accuracy: 94.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|████▋     | 250/531 [13:34<15:11,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250, Loss: 0.0586, Accuracy: 94.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▋    | 300/531 [16:17<12:20,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300, Loss: 0.1919, Accuracy: 94.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|██████▌   | 350/531 [18:59<09:41,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 350, Loss: 0.1677, Accuracy: 94.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 400/531 [21:47<07:22,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400, Loss: 0.3949, Accuracy: 94.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▍ | 450/531 [24:33<04:20,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 450, Loss: 0.1798, Accuracy: 94.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 500/531 [27:16<01:40,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500, Loss: 0.0836, Accuracy: 94.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 531/531 [28:55<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 531 batches\n",
      "Training Loss: 0.1606, Accuracy: 94.12%\n",
      "Training Loss: 0.1606, Training Accuracy: 94.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 263/263 [05:18<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.37%\n",
      "Precision: 0.6274\n",
      "Recall: 0.8487\n",
      "F1-Score: 0.7215\n",
      "Confusion Matrix:\n",
      "[[6554  623]\n",
      " [ 187 1049]]\n",
      "Validation Accuracy: 90.37%, F1-Score: 0.7215\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 50/531 [02:42<26:33,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50, Loss: 0.1243, Accuracy: 95.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 100/531 [05:24<23:28,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100, Loss: 0.3724, Accuracy: 95.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 150/531 [08:05<20:26,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 150, Loss: 0.1765, Accuracy: 95.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 200/531 [10:47<17:50,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200, Loss: 0.0308, Accuracy: 95.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|████▋     | 250/531 [13:28<15:09,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250, Loss: 0.1020, Accuracy: 95.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▋    | 300/531 [16:09<12:26,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300, Loss: 0.0572, Accuracy: 95.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|██████▌   | 350/531 [18:50<09:40,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 350, Loss: 0.1468, Accuracy: 95.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 400/531 [21:32<07:01,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400, Loss: 0.1820, Accuracy: 95.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▍ | 450/531 [24:13<04:20,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 450, Loss: 0.1296, Accuracy: 95.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 500/531 [26:54<01:39,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500, Loss: 0.1545, Accuracy: 95.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 531/531 [28:30<00:00,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 531 batches\n",
      "Training Loss: 0.1238, Accuracy: 95.78%\n",
      "Training Loss: 0.1238, Training Accuracy: 95.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 263/263 [05:14<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.34%\n",
      "Precision: 0.5941\n",
      "Recall: 0.8657\n",
      "F1-Score: 0.7046\n",
      "Confusion Matrix:\n",
      "[[6446  731]\n",
      " [ 166 1070]]\n",
      "Validation Accuracy: 89.34%, F1-Score: 0.7046\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 50/531 [02:41<25:40,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50, Loss: 0.1021, Accuracy: 96.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 100/531 [05:22<23:08,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100, Loss: 0.1184, Accuracy: 96.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 150/531 [08:04<20:26,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 150, Loss: 0.0694, Accuracy: 95.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 200/531 [10:46<17:44,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200, Loss: 0.0262, Accuracy: 95.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|████▋     | 250/531 [13:27<15:03,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250, Loss: 0.1234, Accuracy: 95.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▋    | 300/531 [16:11<12:27,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300, Loss: 0.0600, Accuracy: 95.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|██████▌   | 350/531 [18:52<09:45,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 350, Loss: 0.0294, Accuracy: 95.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 400/531 [21:36<07:02,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400, Loss: 0.1299, Accuracy: 95.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▍ | 450/531 [24:19<04:22,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 450, Loss: 0.1536, Accuracy: 95.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 500/531 [27:04<01:44,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500, Loss: 0.0903, Accuracy: 96.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 531/531 [28:42<00:00,  3.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 531 batches\n",
      "Training Loss: 0.1179, Accuracy: 95.95%\n",
      "Training Loss: 0.1179, Training Accuracy: 95.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 263/263 [05:13<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.04%\n",
      "Precision: 0.5857\n",
      "Recall: 0.8681\n",
      "F1-Score: 0.6995\n",
      "Confusion Matrix:\n",
      "[[6418  759]\n",
      " [ 163 1073]]\n",
      "Validation Accuracy: 89.04%, F1-Score: 0.6995\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 50/531 [02:45<26:59,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50, Loss: 0.0879, Accuracy: 95.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 100/531 [05:31<23:14,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100, Loss: 0.1965, Accuracy: 95.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 150/531 [08:19<21:13,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 150, Loss: 0.3719, Accuracy: 95.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 200/531 [11:09<17:43,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200, Loss: 0.2968, Accuracy: 95.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|████▋     | 250/531 [13:58<15:43,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250, Loss: 0.0856, Accuracy: 96.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▋    | 300/531 [16:39<12:19,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300, Loss: 0.0237, Accuracy: 96.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|██████▌   | 350/531 [19:20<09:43,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 350, Loss: 0.1392, Accuracy: 96.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 400/531 [22:14<07:12,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400, Loss: 0.0715, Accuracy: 96.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▍ | 450/531 [25:21<05:45,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 450, Loss: 0.2055, Accuracy: 96.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 500/531 [28:06<01:39,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500, Loss: 0.1421, Accuracy: 96.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 531/531 [29:53<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 531 batches\n",
      "Training Loss: 0.1142, Accuracy: 96.12%\n",
      "Training Loss: 0.1142, Training Accuracy: 96.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 263/263 [05:26<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.85%\n",
      "Precision: 0.5805\n",
      "Recall: 0.8697\n",
      "F1-Score: 0.6962\n",
      "Confusion Matrix:\n",
      "[[6400  777]\n",
      " [ 161 1075]]\n",
      "Validation Accuracy: 88.85%, F1-Score: 0.6962\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 50/531 [02:44<26:52,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50, Loss: 0.1025, Accuracy: 95.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 100/531 [05:25<23:54,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100, Loss: 0.0862, Accuracy: 96.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 150/531 [08:11<21:07,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 150, Loss: 0.0681, Accuracy: 96.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 200/531 [11:00<18:04,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200, Loss: 0.1324, Accuracy: 96.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|████▋     | 250/531 [13:43<15:03,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250, Loss: 0.2490, Accuracy: 96.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▋    | 300/531 [16:27<12:24,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300, Loss: 0.0142, Accuracy: 96.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  66%|██████▌   | 350/531 [19:14<09:45,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 350, Loss: 0.1461, Accuracy: 96.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 400/531 [22:00<07:03,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400, Loss: 0.0755, Accuracy: 96.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▍ | 450/531 [24:41<04:19,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 450, Loss: 0.3194, Accuracy: 96.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|█████████▍| 500/531 [27:23<01:39,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500, Loss: 0.2029, Accuracy: 96.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 531/531 [29:00<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 531 batches\n",
      "Training Loss: 0.1126, Accuracy: 96.29%\n",
      "Training Loss: 0.1126, Training Accuracy: 96.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 263/263 [05:18<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.07%\n",
      "Precision: 0.5601\n",
      "Recall: 0.8746\n",
      "F1-Score: 0.6829\n",
      "Confusion Matrix:\n",
      "[[6328  849]\n",
      " [ 155 1081]]\n",
      "Validation Accuracy: 88.07%, F1-Score: 0.6829\n",
      "\n",
      "Training completed in 351.28 minutes\n",
      "Best validation accuracy: 93.91%\n",
      "----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf845cd6",
   "metadata": {},
   "source": [
    "Evaluate Model using Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87b2a7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "📊 Evaluation for TRAIN\n",
      "Accuracy: 0.9712989156058462\n",
      "Precision: 0.9859035119698627\n",
      "Recall: 0.9562706270627063\n",
      "F1-Score: 0.9708610064022019\n",
      "AUC-ROC: 0.9934172272804165\n",
      "Confusion Matrix: [[8368, 116], [371, 8113]]\n",
      "\n",
      "📊 Evaluation for VAL\n",
      "Accuracy: 0.8806608819683822\n",
      "Precision: 0.5601036269430052\n",
      "Recall: 0.8745954692556634\n",
      "F1-Score: 0.6828806064434618\n",
      "AUC-ROC: 0.9540645391404492\n",
      "Confusion Matrix: [[6328, 849], [155, 1081]]\n",
      "\n",
      "📊 Evaluation for TEST\n",
      "Accuracy: 0.8771241830065359\n",
      "Precision: 0.5652392947103274\n",
      "Recall: 0.8677494199535963\n",
      "F1-Score: 0.6845637583892618\n",
      "AUC-ROC: 0.9481623230785171\n",
      "Confusion Matrix: [[6259, 863], [171, 1122]]\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Training and evaluation completed!\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "print(\"Evaluating on test set...\")\n",
    "\n",
    "# Use the updated weights parameter instead of deprecated 'pretrained'\n",
    "weights = MobileNet_V3_Large_Weights.DEFAULT\n",
    "model = mobilenet_v3_large(weights=weights)\n",
    "model.classifier[3] = nn.Linear(model.classifier[3].in_features, 2)  # 2 classes: cracked / not cracked\n",
    "\n",
    "# Load trained weights\n",
    "model.load_state_dict(torch.load('../model/Optimize_MobileNetV3_concrete_crack_detector.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Define the transform for test data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model_on_split(split_name):\n",
    "    base_path = f\"../artifact_folder/{split_name}\"\n",
    "    labels_df = pd.read_csv(os.path.join(base_path, \"labels.csv\"))\n",
    "    images_dir = os.path.join(base_path, \"images\")\n",
    "\n",
    "    y_true, y_pred, y_score = [], [], []\n",
    "\n",
    "    for _, row in labels_df.iterrows():\n",
    "        img_path = os.path.join(images_dir, row[\"filename\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            pred = output.argmax(dim=1).item()\n",
    "            prob = torch.softmax(output, dim=1)[0][1].item()\n",
    "\n",
    "        label = 1 if row[\"label\"].lower() == \"cracked\" else 0\n",
    "        y_true.append(label)\n",
    "        y_pred.append(pred)\n",
    "        y_score.append(prob)\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"F1-Score\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"AUC-ROC\": roc_auc_score(y_true, y_score),\n",
    "        \"Confusion Matrix\": confusion_matrix(y_true, y_pred).tolist()\n",
    "    }\n",
    "\n",
    "# Run on all sets\n",
    "for split in ['train', 'val', 'test']:\n",
    "    print(f\"📊 Evaluation for {split.upper()}\")\n",
    "    metrics = evaluate_model_on_split(split)\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    print()\n",
    "print(f\"----------------------------------------------------------------------------\")\n",
    "print(\"Training and evaluation completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
